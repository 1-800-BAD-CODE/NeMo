
init_from_nemo_model: nemo_exp/token/two_pass/2022-09-27_17-54-32/checkpoints/two_pass.nemo
#init_from_nemo_model:
#  model0:
#    path: nemo_exp/token/test_tokens_1/2022-08-19_20-10-19/checkpoints/test_tokens_1.nemo
#    exclude: [
#      "_punct_post_loss.weight",
#      "_punct_head_post"
#    ]
name: "two_pass"

model:
  # For reference only
  supported_languages: [
      "ar", "de", "es", "en", "fr", "hi", "it", "ja", "ru", "uk", "zh",
      "bs", "cs", "et", "fi", "is", "lt", "lv", "pl", "pt", "ro", "tr"
  ]
  multipass: true  # train with two passes

  tokenizer:
    special_tokens: null
    tokenizer_name: ${model.language_model.pretrained_model_name}
    tokenizer_model: null
    vocab_file: null

  language_model:
    config_file: null
    pretrained_model_name: bert-base-multilingual-cased
    nemo_file: null
    lm_checkpoint: null
    vocab_file: null
    config: null

  # Optionally we can learn the exclamation marks ["!", "！", "¡"]. If not using them, specify them as 'unused' so that
  # the datasets will not filter out sentences that end in '!', and therefore the model will not barf when seeing these
  # for the first time during inference.
  unused_punctuation: ["!", "！", "¡"]
  null_punct_token: "<NULL>"
  # Punctuation tokens that are predicted before each subword. Add "¡" here if using it.
  punct_pre_labels: ["<NULL>", "¿",]
  # Punctuation tokens that are predicted after each subword. Note the datasets below are configured to map the Chinese
  # enumeration comma to a regular Chinese comma, due to inconsistencies in the raw data, so it is not learned.
  punct_post_labels: [
      "<NULL>",
      ".", ",", "?",
      "？", "，", "。", # Chinese, no enum comma
      "、", "・",  # Japanese comma, middle dot
      "।", # Hindi
      "؟",  # Arabic
      "՞", # Armenian (placeholder for fine-tuning later; currently not trained with Armenian)
      ";",  # Greek question mark (placeholder; remove from all other languages during training)
      "።",  # Amharic full stop (placeholder)
  ]
  loss:
    # Loss weights for punct_post_labels
    punct_post:
      # This would be more convenient with a dict. Values are aligned to punctuation.
      weight: [
          0.5,
          3, 3, 4,
          4, 3, 4,
          3, 5,
          3,
          4,
          1, 1, 1 # 3 placeholder punctuation tokens
      ]
    # Loss weights for punct_pre_labels
    punct_pre:
      weight: [0.5, 4.0]
    # Loss weights for [lower_case, upper_case]
    cap:
      weight: [0.5, 5.0]
    # Loss weights for [no_stop, full_stop]
    seg:
      weight: [0.5, 4.0]
  # Target padding value. No need to change.
  pad_value: -100

  train_ds:
    batch_size: 32
    num_workers: 6
    # A list of datasets will be used to create a ConcatDataset.
    sampling_technique: "temperature"
    sampling_temperature: 5
    # "common" key/value pairs will be added to every data set, unless that dataset already specifies the key.
    common:
      max_lines_per_input_file: 200000
      punct_pre_labels: ${model.punct_pre_labels}
      punct_post_labels: ${model.punct_post_labels}
      unused_punctuation: ${model.unused_punctuation}
      min_lines_per_eg: 2
      max_lines_per_eg: 6
      max_length: 128
      truncate_max_tokens: 0
    # Same as "common", but only for continuous-script languages
    common_continuous_script:
      min_input_length_chars: 2  # Need at least 2 to have char + punctuation
      max_input_length_chars: 64
    # Same as "common", but only for non continuous-script languages
    common_noncontinuous_script:
      min_input_length_words: 1
      max_input_length_words: 40
    # Typically, set up one data set per language.
    datasets:
      # targets can be any implementation of a PunctCapSegDataset; only TextPunctCapSegDataset is fully implemented.
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        # One or more unprocessed, plain-text files containing one sentence per line
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.en.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/en/train.txt"
#          - "/home/shane/corpora/opensub/en/train.txt"
        # Will be used to select the punctuation targets generator, which is language-specific.
        language: "en"
        # List of zero or more implementations of nlp.data.token_classification.punct_cap_seg_dataset.TextCleaner
        cleaners:
          # Remove ';' because it has a special meaning for greek punctuation, not used in other languages
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.ru.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/ru/train.txt"
#          - "/home/shane/corpora/opensub/ru/train.txt"
        language: "ru"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.de.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/de/train.txt"
#          - "/home/shane/corpora/opensub/de/train.txt"
        language: "de"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.it.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/it/train.txt"
#          - "/home/shane/corpora/opensub/it/train.txt"
        language: "it"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.fr.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/fr/train.txt"
#          - "/home/shane/corpora/opensub/fr/train.txt"
        language: "fr"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.uk.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/uk/train.txt"
#          - "/home/shane/corpora/opensub/uk/train.txt"
        language: "uk"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.ar.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/ar/train.txt"
#          - "/home/shane/corpora/opensub/ar/train.txt"
        language: "ar"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.ArabicTextCleaner
            replace_latin: true
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.hi.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/hi/hi.txt"
#          - "/home/shane/corpora/opensub/hi/train.txt"
        language: "hi"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.HindiTextCleaner
            no_double_danda: true
            replace_latin: true
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.es.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/es/train.txt"
#          - "/home/shane/corpora/opensub/es/train.txt"
        language: "es"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.SpanishPunctNormalizer
            pre_punct_tokens: ${model.punct_pre_labels}
            post_punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.zh.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/zh/train.txt"
#          - "/home/shane/corpora/opensub/zh/train.txt"
        language: "zh"
        # Let dataset know this is a continuous-script language
        is_continuous: true
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.ChineseTextCleaner
            remove_spaces: true
            replace_latin: true
            no_enum_comma: true
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.ja.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/ja/train.txt"
#          - "/home/shane/corpora/opensub/ja/train.txt"
        language: "ja"
        is_continuous: true
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.JapaneseTextCleaner
            replace_latin: true
            remove_spaces: true
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      # "bs", "cs", "et", "fi", "is", "lt", "lv", "pl", "pt", "ro", "tr"
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.bs.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/bs/bs.txt"
#          - "/home/shane/corpora/opensub/bs/train.txt"
        language: "bs"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.cs.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/cs/train.txt"
#          - "/home/shane/corpora/opensub/cs/train.txt"
        language: "cs"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.et.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/et/et.txt"
#          - "/home/shane/corpora/opensub/et/train.txt"
        language: "et"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.fi.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/fi/train.txt"
#          - "/home/shane/corpora/opensub/fi/train.txt"
        language: "fi"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.is.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/is/is.txt"
#          - "/home/shane/corpora/opensub/is/train.txt"
        language: "is"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.lt.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/lt/train.txt"
#          - "/home/shane/corpora/opensub/lt/train.txt"
        language: "lt"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.lv.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/lv/lv.txt"
#          - "/home/shane/corpora/opensub/lv/train.txt"
        language: "lv"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.pl.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/pl/train.txt"
#          - "/home/shane/corpora/opensub/pl/train.txt"
        language: "pl"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.pt.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/pt/pt.txt"
#          - "/home/shane/corpora/opensub/pt/train.txt"
        language: "pt"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.ro.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/ro/ro.txt"
#          - "/home/shane/corpora/opensub/ro/train.txt"
        language: "ro"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.tr.shuffled.deduped"
          - "/home/shane/corpora/tatoeba/tr/train.txt"
#          - "/home/shane/corpora/opensub/tr/train.txt"
        language: "tr"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}

  validation_ds:
    batch_size: 40
    num_workers: 6
    common:
      max_lines_per_input_file: 400000
      punct_pre_labels: ${model.punct_pre_labels}
      punct_post_labels: ${model.punct_post_labels}
      unused_punctuation: ${model.unused_punctuation}
      min_lines_per_eg: 2
      max_lines_per_eg: 6
      max_length: 128
      truncate_max_tokens: 0
      rng_seed: 12345
    common_continuous_script:
      min_input_length_chars: 2
      max_input_length_chars: 64
    common_noncontinuous_script:
      min_input_length_words: 1
      max_input_length_words: 40
    datasets:
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.en.shuffled.deduped.tail2k"
        language: "en"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.ru.shuffled.deduped.tail2k"
        language: "ru"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.de.shuffled.deduped.tail2k"
        language: "de"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.it.shuffled.deduped.tail2k"
        language: "it"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.fr.shuffled.deduped.tail2k"
        language: "fr"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.uk.shuffled.deduped.tail2k"
        language: "uk"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.ar.shuffled.deduped.tail2k"
        language: "ar"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.ArabicTextCleaner
            replace_latin: true
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.hi.shuffled.deduped.tail2k"
        language: "hi"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.HindiTextCleaner
            no_double_danda: true
            replace_latin: true
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.es.shuffled.deduped.tail2k"
        language: "es"
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.SpanishPunctNormalizer
            pre_punct_tokens: ${model.punct_pre_labels}
            post_punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.zh.shuffled.deduped.tail2k"
        language: "zh"
        # Let dataset know this is a continuous-script language
        is_continuous: true
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.ChineseTextCleaner
            remove_spaces: true
            replace_latin: true
            no_enum_comma: true
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
        text_files:
          - "/home/shane/corpora/wmt_nc/news.2021.ja.shuffled.deduped.tail2k"
        language: "ja"
        is_continuous: true
        cleaners:
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
            chars_to_remove: [";", '"']
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.JapaneseTextCleaner
            replace_latin: true
            remove_spaces: true
          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
            punct_tokens: ${model.punct_post_labels}
      # "bs", "cs", "et", "fi", "is", "lt", "lv", "pl", "pt", "ro", "tr"
#      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
#        text_files:
#          - "/home/shane/corpora/opensub/bs/dev.txt"
#        language: "bs"
#        cleaners:
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
#            chars_to_remove: [";", '"']
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
#            punct_tokens: ${model.punct_post_labels}
#      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
#        text_files:
#          - "/home/shane/corpora/opensub/cs/dev.txt"
#        language: "cs"
#        cleaners:
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
#            chars_to_remove: [";", '"']
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
#            punct_tokens: ${model.punct_post_labels}
#      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
#        text_files:
#          - "/home/shane/corpora/opensub/et/dev.txt"
#        language: "et"
#        cleaners:
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
#            chars_to_remove: [";", '"']
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
#            punct_tokens: ${model.punct_post_labels}
#      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
#        text_files:
#          - "/home/shane/corpora/opensub/fi/dev.txt"
#        language: "fi"
#        cleaners:
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
#            chars_to_remove: [";", '"']
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
#            punct_tokens: ${model.punct_post_labels}
#      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
#        text_files:
#          - "/home/shane/corpora/opensub/is/dev.txt"
#        language: "is"
#        cleaners:
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
#            chars_to_remove: [";", '"']
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
#            punct_tokens: ${model.punct_post_labels}
#      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
#        text_files:
#          - "/home/shane/corpora/opensub/lt/dev.txt"
#        language: "lt"
#        cleaners:
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
#            chars_to_remove: [";", '"']
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
#            punct_tokens: ${model.punct_post_labels}
#      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
#        text_files:
#          - "/home/shane/corpora/opensub/lv/dev.txt"
#        language: "lv"
#        cleaners:
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
#            chars_to_remove: [";", '"']
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
#            punct_tokens: ${model.punct_post_labels}
#      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
#        text_files:
#          - "/home/shane/corpora/opensub/pl/dev.txt"
#        language: "pl"
#        cleaners:
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
#            chars_to_remove: [";", '"']
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
#            punct_tokens: ${model.punct_post_labels}
#      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
#        text_files:
#          - "/home/shane/corpora/opensub/pt/dev.txt"
#        language: "pt"
#        cleaners:
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
#            chars_to_remove: [";", '"']
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
#            punct_tokens: ${model.punct_post_labels}
#      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
#        text_files:
#          - "/home/shane/corpora/opensub/ro/dev.txt"
#        language: "ro"
#        cleaners:
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
#            chars_to_remove: [";", '"']
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
#            punct_tokens: ${model.punct_post_labels}
#      - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.TextPunctCapSegDataset
#        text_files:
#          - "/home/shane/corpora/opensub/tr/dev.txt"
#        language: "tr"
#        cleaners:
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.CharFilter
#            chars_to_remove: [";", '"']
#          - _target_: nemo.collections.nlp.data.token_classification.punct_cap_seg_dataset.StandardPunctNormalizer
#            punct_tokens: ${model.punct_post_labels}

  punct_head_pre:
    num_layers: 1
    activation: relu
    dropout: 0.1
    use_transformer_init: true

  punct_head_post:
    num_layers: 1
    activation: relu
    dropout: 0.1
    use_transformer_init: true

  cap_head:
    num_layers: 1
    activation: relu
    dropout: 0.1
    use_transformer_init: true

  seg_head:
    num_layers: 1
    activation: relu
    dropout: 0.1
    use_transformer_init: true

  optim:
    name: adam
    lr: 2e-5  #
    weight_decay: 0  # 5e-4
    sched:
      name: WarmupAnnealing
      min_lr: 1e-6
      last_epoch: -1
      warmup_ratio: null
      warmup_steps: 6000

trainer:
  devices: -1
  num_nodes: 1
  max_epochs: 1
  max_steps: 50000
  accumulate_grad_batches: 1
  gradient_clip_val: 0.0
  precision: 16 # Should be set to 16 for O1 and O2, default is 16 as PT ignores it when am_level is O0
  accelerator: auto
  log_every_n_steps: 250  # Interval of logging.
  val_check_interval: 5000  # Set to 0.25 to check 4 times per epoch, or an int for number of iterations
  resume_from_checkpoint: null
  logger: false
  enable_checkpointing: false
  progress_bar_refresh_rate: 10
  benchmark: false

exp_manager:
  exp_dir: nemo_exp/token/
  name: ${name}
  create_tensorboard_logger: true
  create_checkpoint_callback: true
  # Available metrics are val_{language}_{punct_pre,punct_post,cap,seg}_{f1,precision,recall}
  # TODO use average metrics all languages
  checkpoint_callback_params:
    monitor: "val_en_punct_post_f1"
    mode: "max"
    save_top_k: 2
    always_save_nemo: true
#  # for continuing
#  version: 2022-10-03_16-56-33
#  resume_if_exists: true
#  resume_ignore_no_checkpoint: false
